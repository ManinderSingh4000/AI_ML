{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1Yfa6RcoT7VfUbT69370JYJhfSyRKwVec",
      "authorship_tag": "ABX9TyM7ZRW7fBLbIcTU6VKfxSF8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "44e030ae4208425b85e3f65bd771cd07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9e87ec48a13e4da7b59263b278b55c55",
              "IPY_MODEL_577e47a68a8e49cebd47b5d76d87e4fc",
              "IPY_MODEL_2c4a911ad9c04f14ad444041fc78f8ac"
            ],
            "layout": "IPY_MODEL_a41d898a20bf4edeb22f92a7bbe9a034"
          }
        },
        "9e87ec48a13e4da7b59263b278b55c55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8462263120f94edfb66570f0701a8e2d",
            "placeholder": "​",
            "style": "IPY_MODEL_2bb855b633d8455c94c0641a0504cd78",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "577e47a68a8e49cebd47b5d76d87e4fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f1307f0f45946e4958ad6cdeb0a7e3d",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f8faf7e2481144c8be7df7ed53cc3334",
            "value": 48
          }
        },
        "2c4a911ad9c04f14ad444041fc78f8ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5714bb0f1d4442f0b293ef272b305aaf",
            "placeholder": "​",
            "style": "IPY_MODEL_6a41d47dc3d94ca8a30f481f64e86b61",
            "value": " 48.0/48.0 [00:00&lt;00:00, 1.30kB/s]"
          }
        },
        "a41d898a20bf4edeb22f92a7bbe9a034": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8462263120f94edfb66570f0701a8e2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bb855b633d8455c94c0641a0504cd78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f1307f0f45946e4958ad6cdeb0a7e3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8faf7e2481144c8be7df7ed53cc3334": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5714bb0f1d4442f0b293ef272b305aaf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a41d47dc3d94ca8a30f481f64e86b61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6cdbb438123f42be8e97eceafc7335a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c1d4bd1daa654145b3ec64d90636880c",
              "IPY_MODEL_d48d56f60f724be98d0a670087c731c5",
              "IPY_MODEL_1fbd034471fe4d1b86b3580587c2f2cd"
            ],
            "layout": "IPY_MODEL_e5ebe9aff10f4f35b430df847dc8e8c8"
          }
        },
        "c1d4bd1daa654145b3ec64d90636880c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c24697f4ae8d42b8a52bcb66b74ffc13",
            "placeholder": "​",
            "style": "IPY_MODEL_3b8f330a2a364ef98beb8ea3952f5a38",
            "value": "config.json: 100%"
          }
        },
        "d48d56f60f724be98d0a670087c731c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f13735033c39468ca55f9b5cac332c65",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_805eac400eab436eb991c8b50326c0cd",
            "value": 570
          }
        },
        "1fbd034471fe4d1b86b3580587c2f2cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1bbd031ec1e24fc2a4ef6347b2a757e0",
            "placeholder": "​",
            "style": "IPY_MODEL_62c2903ab1a04d7baae62d38b45d4057",
            "value": " 570/570 [00:00&lt;00:00, 13.5kB/s]"
          }
        },
        "e5ebe9aff10f4f35b430df847dc8e8c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c24697f4ae8d42b8a52bcb66b74ffc13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b8f330a2a364ef98beb8ea3952f5a38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f13735033c39468ca55f9b5cac332c65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "805eac400eab436eb991c8b50326c0cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1bbd031ec1e24fc2a4ef6347b2a757e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62c2903ab1a04d7baae62d38b45d4057": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a07eca14c0cf4580bfb0276b7d8aeace": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d6c39277edac45e28bdb7f0e17130f59",
              "IPY_MODEL_7cadbe1533844050a0aa49e075f67b6b",
              "IPY_MODEL_11d9454df60747a79a741050c2f659d1"
            ],
            "layout": "IPY_MODEL_6df507f232fa49ccbe249ad510b2892e"
          }
        },
        "d6c39277edac45e28bdb7f0e17130f59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5369850a91c94ea695c2b3cd451e2c1f",
            "placeholder": "​",
            "style": "IPY_MODEL_0f7e03e64af54cdd9172ac0a3dbbb78b",
            "value": "vocab.txt: 100%"
          }
        },
        "7cadbe1533844050a0aa49e075f67b6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8d4ad15b4684ab3b6779fe7243dbb40",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_91df583ad1d547838d27a480d14f2c1f",
            "value": 231508
          }
        },
        "11d9454df60747a79a741050c2f659d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_106004c217d94e0cbc09af649a090e8b",
            "placeholder": "​",
            "style": "IPY_MODEL_477b8edc66764b3b858bda4ca9c4f38d",
            "value": " 232k/232k [00:00&lt;00:00, 2.38MB/s]"
          }
        },
        "6df507f232fa49ccbe249ad510b2892e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5369850a91c94ea695c2b3cd451e2c1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f7e03e64af54cdd9172ac0a3dbbb78b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e8d4ad15b4684ab3b6779fe7243dbb40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91df583ad1d547838d27a480d14f2c1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "106004c217d94e0cbc09af649a090e8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "477b8edc66764b3b858bda4ca9c4f38d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cdde2dccf2f347c28d58e8c6dbee019f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_217f38a1115c4cbcb27fe538614bfd12",
              "IPY_MODEL_b0f83d98032f4600b4403f7e87949746",
              "IPY_MODEL_9eaa48fbb1334070bb525564c7457ee2"
            ],
            "layout": "IPY_MODEL_c9d39f888f86406e9cf42c4a10b11c3e"
          }
        },
        "217f38a1115c4cbcb27fe538614bfd12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc48410205c343cea1a26d9335f14052",
            "placeholder": "​",
            "style": "IPY_MODEL_932a01f4d0094acaa097b80d8aab9e17",
            "value": "tokenizer.json: 100%"
          }
        },
        "b0f83d98032f4600b4403f7e87949746": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c0a129424f5474c88ab6ac421c6cfa1",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fa4da4ae3b1e4f77bd590084940cf7df",
            "value": 466062
          }
        },
        "9eaa48fbb1334070bb525564c7457ee2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35f856f1945b4be5afcfb6fc12bb4bf0",
            "placeholder": "​",
            "style": "IPY_MODEL_dcbe6072ffc243bd91ab4be5a212bc36",
            "value": " 466k/466k [00:00&lt;00:00, 5.35MB/s]"
          }
        },
        "c9d39f888f86406e9cf42c4a10b11c3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc48410205c343cea1a26d9335f14052": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "932a01f4d0094acaa097b80d8aab9e17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4c0a129424f5474c88ab6ac421c6cfa1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa4da4ae3b1e4f77bd590084940cf7df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "35f856f1945b4be5afcfb6fc12bb4bf0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcbe6072ffc243bd91ab4be5a212bc36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ManinderSingh4000/AI_ML/blob/main/Guit_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LHlgLEgwmasZ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, LayerNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np\n",
        "\n",
        "# Parameters\n",
        "AUDIO_SEQ_LEN = 2000   # from your MFCC/audio features\n",
        "AUDIO_FEATURE_DIM = 64\n",
        "MAX_TARGET_LEN = 100    # token sequence length of XML/tab\n",
        "VOCAB_SIZE = 500        # depends on tokenizer used on target text\n",
        "EMBED_DIM = 256         # transformer model dimensionality\n",
        "NUM_HEADS = 4\n",
        "FF_DIM = 512\n",
        "NUM_LAYERS = 4\n",
        "DROPOUT_RATE = 0.1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoderBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super().__init__()\n",
        "        self.att = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = tf.keras.Sequential([\n",
        "            Dense(ff_dim, activation=\"relu\"),\n",
        "            Dense(embed_dim),\n",
        "        ])\n",
        "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = Dropout(rate)\n",
        "        self.dropout2 = Dropout(rate)\n",
        "\n",
        "    def call(self, x, training):\n",
        "        attn_output = self.att(x, x)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(x + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "class TransformerDecoderBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super().__init__()\n",
        "        self.att1 = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.att2 = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "\n",
        "        self.ffn = tf.keras.Sequential([\n",
        "            Dense(ff_dim, activation=\"relu\"),\n",
        "            Dense(embed_dim),\n",
        "        ])\n",
        "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm3 = LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = Dropout(rate)\n",
        "        self.dropout2 = Dropout(rate)\n",
        "        self.dropout3 = Dropout(rate)\n",
        "\n",
        "    def call(self, x, enc_output, training, look_ahead_mask=None, padding_mask=None):\n",
        "        attn1 = self.att1(x, x, attention_mask=look_ahead_mask)\n",
        "        attn1 = self.dropout1(attn1, training=training)\n",
        "        out1 = self.layernorm1(x + attn1)\n",
        "\n",
        "        attn2 = self.att2(out1, enc_output)\n",
        "        attn2 = self.dropout2(attn2, training=training)\n",
        "        out2 = self.layernorm2(out1 + attn2)\n",
        "\n",
        "        ffn_output = self.ffn(out2)\n",
        "        ffn_output = self.dropout3(ffn_output, training=training)\n",
        "        return self.layernorm3(out2 + ffn_output)\n"
      ],
      "metadata": {
        "id": "G0mjgmW5nDpI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "def get_positional_encoding(seq_len, d_model):\n",
        "    pos = np.arange(seq_len)[:, np.newaxis]\n",
        "    i = np.arange(d_model)[np.newaxis, :]\n",
        "    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
        "    angle_rads = pos * angle_rates\n",
        "\n",
        "    # Apply sin to even indices, cos to odd indices\n",
        "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    pos_encoding = angle_rads[np.newaxis, ...]\n",
        "    return tf.cast(pos_encoding, dtype=tf.float32)\n",
        "\n",
        "class PositionalEmbedding(tf.keras.layers.Layer):\n",
        "    def __init__(self, vocab_size, max_len, d_model):\n",
        "        super().__init__()\n",
        "        self.token_embedding = tf.keras.layers.Embedding(vocab_size, d_model)\n",
        "        self.pos_encoding = get_positional_encoding(max_len, d_model)\n",
        "\n",
        "    def call(self, x):\n",
        "        length = tf.shape(x)[1]\n",
        "        x = self.token_embedding(x)\n",
        "        return x + self.pos_encoding[:, :length, :]\n"
      ],
      "metadata": {
        "id": "IaLQstNpnGd2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_transformer_model(\n",
        "    audio_seq_len=2000,\n",
        "    audio_feat_dim=64,\n",
        "    max_target_len=100,\n",
        "    vocab_size=500,\n",
        "    embed_dim=256,\n",
        "    ff_dim=512,\n",
        "    num_heads=4,\n",
        "    num_layers=4,\n",
        "    dropout_rate=0.1,\n",
        "):\n",
        "    # ==== AUDIO ENCODER ====\n",
        "    encoder_input = Input(shape=(audio_seq_len, audio_feat_dim), name=\"audio_input\")\n",
        "    x = Dense(embed_dim)(encoder_input)  # Project audio features to model dimension\n",
        "    x += get_positional_encoding(audio_seq_len, embed_dim)[:, :audio_seq_len, :]\n",
        "\n",
        "    for _ in range(num_layers):\n",
        "        x = TransformerEncoderBlock(embed_dim, num_heads, ff_dim, dropout_rate)(x, training=True)\n",
        "    encoder_output = x\n",
        "\n",
        "    # ==== TEXT DECODER ====\n",
        "    decoder_input = Input(shape=(max_target_len,), name=\"decoder_input\")  # token ids\n",
        "    y = PositionalEmbedding(vocab_size, max_target_len, embed_dim)(decoder_input)\n",
        "\n",
        "    for _ in range(num_layers):\n",
        "        y = TransformerDecoderBlock(embed_dim, num_heads, ff_dim, dropout_rate)(\n",
        "            y, encoder_output, training=True\n",
        "        )\n",
        "\n",
        "    # Output logits over vocabulary\n",
        "    decoder_output = Dense(vocab_size, activation='softmax')(y)\n",
        "\n",
        "    model = Model(inputs=[encoder_input, decoder_input], outputs=decoder_output)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "8NaDL7VunIXW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer = build_transformer_model()\n",
        "\n",
        "transformer.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n"
      ],
      "metadata": {
        "id": "v7HCkTUSnLHW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 770
        },
        "id": "sPZB23z8nNWG",
        "outputId": "ee25c767-b52c-442e-fd1e-fdefaa3edae5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_8\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_8\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ audio_input         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m, \u001b[38;5;34m256\u001b[0m) │     \u001b[38;5;34m16,640\u001b[0m │ audio_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add (\u001b[38;5;33mAdd\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ transformer_encode… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m, \u001b[38;5;34m256\u001b[0m) │  \u001b[38;5;34m1,315,840\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mTransformerEncode…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ transformer_encode… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m, \u001b[38;5;34m256\u001b[0m) │  \u001b[38;5;34m1,315,840\u001b[0m │ transformer_enco… │\n",
              "│ (\u001b[38;5;33mTransformerEncode…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ transformer_encode… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m, \u001b[38;5;34m256\u001b[0m) │  \u001b[38;5;34m1,315,840\u001b[0m │ transformer_enco… │\n",
              "│ (\u001b[38;5;33mTransformerEncode…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ positional_embeddi… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │    \u001b[38;5;34m128,000\u001b[0m │ decoder_input[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mPositionalEmbeddi…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ transformer_encode… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m, \u001b[38;5;34m256\u001b[0m) │  \u001b[38;5;34m1,315,840\u001b[0m │ transformer_enco… │\n",
              "│ (\u001b[38;5;33mTransformerEncode…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ transformer_decode… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │  \u001b[38;5;34m2,368,256\u001b[0m │ positional_embed… │\n",
              "│ (\u001b[38;5;33mTransformerDecode…\u001b[0m │                   │            │ transformer_enco… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ transformer_decode… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │  \u001b[38;5;34m2,368,256\u001b[0m │ transformer_deco… │\n",
              "│ (\u001b[38;5;33mTransformerDecode…\u001b[0m │                   │            │ transformer_enco… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ transformer_decode… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │  \u001b[38;5;34m2,368,256\u001b[0m │ transformer_deco… │\n",
              "│ (\u001b[38;5;33mTransformerDecode…\u001b[0m │                   │            │ transformer_enco… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ transformer_decode… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │  \u001b[38;5;34m2,368,256\u001b[0m │ transformer_deco… │\n",
              "│ (\u001b[38;5;33mTransformerDecode…\u001b[0m │                   │            │ transformer_enco… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m500\u001b[0m)  │    \u001b[38;5;34m128,500\u001b[0m │ transformer_deco… │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ audio_input         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> │ audio_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ transformer_encode… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,315,840</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ transformer_encode… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,315,840</span> │ transformer_enco… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ transformer_encode… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,315,840</span> │ transformer_enco… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ positional_embeddi… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">128,000</span> │ decoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbeddi…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ transformer_encode… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,315,840</span> │ transformer_enco… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ transformer_decode… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,368,256</span> │ positional_embed… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecode…</span> │                   │            │ transformer_enco… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ transformer_decode… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,368,256</span> │ transformer_deco… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecode…</span> │                   │            │ transformer_enco… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ transformer_decode… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,368,256</span> │ transformer_deco… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecode…</span> │                   │            │ transformer_enco… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ transformer_decode… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,368,256</span> │ transformer_deco… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecode…</span> │                   │            │ transformer_enco… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">128,500</span> │ transformer_deco… │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m15,009,524\u001b[0m (57.26 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,009,524</span> (57.26 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m15,009,524\u001b[0m (57.26 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,009,524</span> (57.26 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_decoder_inputs_outputs(tokenized_targets, start_token_id):\n",
        "    \"\"\"\n",
        "    Takes target sequences (e.g., [34, 76, 12, 9, ...]) and returns:\n",
        "    decoder_input: [<start>, 34, 76, 12, ...]\n",
        "    decoder_output: [34, 76, 12, 9, ...]\n",
        "    \"\"\"\n",
        "    decoder_inputs = []\n",
        "    decoder_outputs = []\n",
        "\n",
        "    for seq in tokenized_targets:\n",
        "        decoder_inputs.append([start_token_id] + seq[:-1])\n",
        "        decoder_outputs.append(seq)\n",
        "\n",
        "    return np.array(decoder_inputs), np.array(decoder_outputs)\n"
      ],
      "metadata": {
        "id": "V_Tr3k1NnPJW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "\n",
        "# Assume you have a list of string targets (e.g., XML or tablature format)\n",
        "# Example:\n",
        "text_targets = [\n",
        "    \"<note><onsetSec>6.605</onsetSec></note>\",\n",
        "    \"<note><onsetSec>7.230</onsetSec></note>\",\n",
        "    \"E|--0--2--3--|\",\n",
        "    # etc.\n",
        "]\n",
        "\n",
        "# Use character-level tokenizer (or switch to word-level if preferred)\n",
        "tokenizer = Tokenizer(char_level=True, filters='', lower=False)\n",
        "tokenizer.fit_on_texts(text_targets)\n",
        "\n",
        "# Convert each string to a list of token IDs\n",
        "Y_token = tokenizer.texts_to_sequences(text_targets)\n",
        "\n",
        "# Set a maximum length for output sequences\n",
        "MAX_TARGET_LEN = 100\n",
        "Y_token = pad_sequences(Y_token, maxlen=MAX_TARGET_LEN, padding='post')\n",
        "\n",
        "# Update vocabulary size\n",
        "VOCAB_SIZE = len(tokenizer.word_index) + 1\n",
        "start_token_id = tokenizer.word_index.get('<', 1)  # use `<` as start token\n"
      ],
      "metadata": {
        "id": "IT88GG02nSmW"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_decoder_inputs_outputs(tokenized_targets, start_token_id):\n",
        "    decoder_inputs = []\n",
        "    decoder_outputs = []\n",
        "\n",
        "    for seq in tokenized_targets:\n",
        "        decoder_input = [start_token_id] + list(seq[:-1])  # shift right\n",
        "        decoder_output = list(seq)\n",
        "        decoder_inputs.append(decoder_input)\n",
        "        decoder_outputs.append(decoder_output)\n",
        "\n",
        "    return np.array(decoder_inputs), np.array(decoder_outputs)\n",
        "\n",
        "# Apply function\n",
        "decoder_input_data, decoder_output_data = prepare_decoder_inputs_outputs(Y_token, start_token_id)\n",
        "\n",
        "# decoder_output needs to be 3D for sparse_categorical_crossentropy\n",
        "decoder_output_data = decoder_output_data[..., np.newaxis]\n"
      ],
      "metadata": {
        "id": "QfXN2HQ6nUqG"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "# Directory containing your .wav files\n",
        "audio_dir = \"/content/drive/MyDrive/dataset2/audio\"  # change as needed\n",
        "files = [f for f in os.listdir(audio_dir) if f.endswith(\".wav\")]\n",
        "\n",
        "# Parameters\n",
        "MAX_AUDIO_LEN = 2000  # pad/truncate to 2000 time steps\n",
        "N_MFCC = 64           # number of MFCCs to extract\n",
        "\n",
        "def extract_mfcc(file_path, max_len=MAX_AUDIO_LEN, n_mfcc=N_MFCC):\n",
        "    y, sr = librosa.load(file_path, sr=None)\n",
        "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
        "    mfcc = mfcc.T  # shape: (time, 64)\n",
        "\n",
        "    if mfcc.shape[0] < max_len:\n",
        "        # Pad with zeros if shorter\n",
        "        pad_width = max_len - mfcc.shape[0]\n",
        "        mfcc = np.pad(mfcc, ((0, pad_width), (0, 0)), mode='constant')\n",
        "    else:\n",
        "        # Truncate if longer\n",
        "        mfcc = mfcc[:max_len, :]\n",
        "\n",
        "    return mfcc\n",
        "\n",
        "# Load all MFCCs\n",
        "X_audio = []\n",
        "for fname in files:\n",
        "    path = os.path.join(audio_dir, fname)\n",
        "    mfcc = extract_mfcc(path)\n",
        "    X_audio.append(mfcc)\n",
        "\n",
        "X_audio = np.array(X_audio)  # final shape: (N, 2000, 64)\n"
      ],
      "metadata": {
        "id": "Ou8SjAqDnWG2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_audio[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phpVwtsrnX1m",
        "outputId": "1903690e-ad29-4cdb-c839-734236d233da"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-5.3748553e+02  0.0000000e+00  0.0000000e+00 ...  0.0000000e+00\n",
            "   0.0000000e+00  0.0000000e+00]\n",
            " [-5.3748553e+02  0.0000000e+00  0.0000000e+00 ...  0.0000000e+00\n",
            "   0.0000000e+00  0.0000000e+00]\n",
            " [-5.3748553e+02  0.0000000e+00  0.0000000e+00 ...  0.0000000e+00\n",
            "   0.0000000e+00  0.0000000e+00]\n",
            " ...\n",
            " [-5.1853265e+02  2.5747753e+01  2.2964104e+01 ... -9.6628135e-01\n",
            "  -1.3735790e+00 -1.3571057e+00]\n",
            " [-5.1610760e+02  2.8187939e+01  2.3252743e+01 ... -9.4099671e-01\n",
            "  -1.5579896e+00 -1.6216792e+00]\n",
            " [-5.1643176e+02  2.7041553e+01  2.0601500e+01 ...  1.4030825e+00\n",
            "   2.4551189e-01 -9.8784566e-02]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Paths to folders\n",
        "audio_dir = \"/content/drive/MyDrive/dataset2/audio\"\n",
        "xml_dir   = \"/content/drive/MyDrive/dataset2/annotation\"\n",
        "\n",
        "X_audio = []\n",
        "text_targets = []\n",
        "\n",
        "# Step 1: Create a set of XML base names\n",
        "xml_files = {os.path.splitext(f)[0] for f in os.listdir(xml_dir) if f.endswith(\".xml\")}\n",
        "\n",
        "# Step 2: Iterate audio files and only include those with matching XML\n",
        "for audio_file in os.listdir(audio_dir):\n",
        "    if audio_file.endswith(\".wav\"):\n",
        "        base_name = os.path.splitext(audio_file)[0]\n",
        "\n",
        "        if base_name in xml_files:\n",
        "            audio_path = os.path.join(audio_dir, audio_file)\n",
        "            xml_path   = os.path.join(xml_dir, base_name + \".xml\")\n",
        "\n",
        "            # --- Process audio ---\n",
        "            y, sr = librosa.load(audio_path, sr=None)\n",
        "            mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=64).T\n",
        "            if mfcc.shape[0] < 2000:\n",
        "                mfcc = np.pad(mfcc, ((0, 2000 - mfcc.shape[0]), (0, 0)), mode='constant')\n",
        "            else:\n",
        "                mfcc = mfcc[:2000, :]\n",
        "            X_audio.append(mfcc)\n",
        "\n",
        "            # --- Process XML ---\n",
        "            with open(xml_path, \"r\", encoding=\"utf-8\") as f:\n",
        "                soup = BeautifulSoup(f, \"xml\")\n",
        "                text_targets.append(str(soup))\n",
        "\n",
        "# Convert to array\n",
        "X_audio = np.array(X_audio)\n",
        "\n",
        "# Final sanity check\n",
        "print(\"✅ Matching files loaded:\")\n",
        "print(f\" - Audio files: {len(X_audio)}\")\n",
        "print(f\" - XML targets: {len(text_targets)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJO52PK3nZ0H",
        "outputId": "5df11787-ba73-4072-8d93-71a86d37e5a3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Matching files loaded:\n",
            " - Audio files: 252\n",
            " - XML targets: 252\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_audio)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5A5UgXrIncFG",
        "outputId": "e7e26c1b-418e-4c89-9122-b1eb9b2d02b8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "252"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Load pre-trained tokenizer (can use T5, BERT, GPT2, etc.)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# Optional: Clean up any empty or malformed XML\n",
        "text_targets = [txt.strip() for txt in text_targets if txt and len(txt.strip()) > 0]\n",
        "\n",
        "# Critical: Match count of inputs and outputs\n",
        "assert len(text_targets) == len(X_audio), f\"Mismatch: {len(text_targets)} targets vs {len(X_audio)} audio\"\n",
        "\n",
        "# Tokenize all XMLs into input_ids\n",
        "Y_token = tokenizer(\n",
        "    text_targets,\n",
        "    return_tensors=\"np\",      # for NumPy (since X_audio is a NumPy array)\n",
        "    padding=\"max_length\",\n",
        "    truncation=True,\n",
        "    max_length=512            # or whatever your Transformer model expects\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274,
          "referenced_widgets": [
            "44e030ae4208425b85e3f65bd771cd07",
            "9e87ec48a13e4da7b59263b278b55c55",
            "577e47a68a8e49cebd47b5d76d87e4fc",
            "2c4a911ad9c04f14ad444041fc78f8ac",
            "a41d898a20bf4edeb22f92a7bbe9a034",
            "8462263120f94edfb66570f0701a8e2d",
            "2bb855b633d8455c94c0641a0504cd78",
            "6f1307f0f45946e4958ad6cdeb0a7e3d",
            "f8faf7e2481144c8be7df7ed53cc3334",
            "5714bb0f1d4442f0b293ef272b305aaf",
            "6a41d47dc3d94ca8a30f481f64e86b61",
            "6cdbb438123f42be8e97eceafc7335a3",
            "c1d4bd1daa654145b3ec64d90636880c",
            "d48d56f60f724be98d0a670087c731c5",
            "1fbd034471fe4d1b86b3580587c2f2cd",
            "e5ebe9aff10f4f35b430df847dc8e8c8",
            "c24697f4ae8d42b8a52bcb66b74ffc13",
            "3b8f330a2a364ef98beb8ea3952f5a38",
            "f13735033c39468ca55f9b5cac332c65",
            "805eac400eab436eb991c8b50326c0cd",
            "1bbd031ec1e24fc2a4ef6347b2a757e0",
            "62c2903ab1a04d7baae62d38b45d4057",
            "a07eca14c0cf4580bfb0276b7d8aeace",
            "d6c39277edac45e28bdb7f0e17130f59",
            "7cadbe1533844050a0aa49e075f67b6b",
            "11d9454df60747a79a741050c2f659d1",
            "6df507f232fa49ccbe249ad510b2892e",
            "5369850a91c94ea695c2b3cd451e2c1f",
            "0f7e03e64af54cdd9172ac0a3dbbb78b",
            "e8d4ad15b4684ab3b6779fe7243dbb40",
            "91df583ad1d547838d27a480d14f2c1f",
            "106004c217d94e0cbc09af649a090e8b",
            "477b8edc66764b3b858bda4ca9c4f38d",
            "cdde2dccf2f347c28d58e8c6dbee019f",
            "217f38a1115c4cbcb27fe538614bfd12",
            "b0f83d98032f4600b4403f7e87949746",
            "9eaa48fbb1334070bb525564c7457ee2",
            "c9d39f888f86406e9cf42c4a10b11c3e",
            "fc48410205c343cea1a26d9335f14052",
            "932a01f4d0094acaa097b80d8aab9e17",
            "4c0a129424f5474c88ab6ac421c6cfa1",
            "fa4da4ae3b1e4f77bd590084940cf7df",
            "35f856f1945b4be5afcfb6fc12bb4bf0",
            "dcbe6072ffc243bd91ab4be5a212bc36"
          ]
        },
        "id": "1rzOPlXMneAF",
        "outputId": "d4deaf1f-6f06-4cce-a563-5b60434b27db"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "44e030ae4208425b85e3f65bd771cd07"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6cdbb438123f42be8e97eceafc7335a3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a07eca14c0cf4580bfb0276b7d8aeace"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cdde2dccf2f347c28d58e8c6dbee019f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# from bs4 import BeautifulSoup\n",
        "# import xml.etree.ElementTree as ET\n",
        "\n",
        "# # Directory with XML files\n",
        "# xml_dir = \"/content/drive/MyDrive/dataset2/annotation\"\n",
        "\n",
        "# # Get all XML file paths\n",
        "# xml_files = [f for f in os.listdir(xml_dir) if f.endswith(\".xml\")]\n",
        "\n",
        "# # Extract XML content as raw strings\n",
        "\n",
        "\n",
        "\n",
        "# text_targets = []\n",
        "\n",
        "# for xml_file in xml_files:\n",
        "#     file_path = os.path.join(xml_dir, xml_file)\n",
        "\n",
        "#     with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "#       xml_content = file.read()\n",
        "#       print(xml_content)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # soup = BeautifulSoup(file, \"xml\")\n",
        "\n",
        "        # # Option 1: Keep full XML as text\n",
        "        # text_targets.append(str(soup))\n",
        "\n",
        "        # Option 2: If you only want specific tags like onsetSec, pitch, etc.:\n",
        "        # notes = soup.find_all(\"note\")\n",
        "        # extracted = \"\"\n",
        "        # for note in notes:\n",
        "        #     extracted += str(note)  # or customize formatting\n",
        "        # text_targets.append(extracted)\n",
        "  # with open(file_path, 'r') as file:\n",
        "          #  xml_content = file.read()"
      ],
      "metadata": {
        "id": "d_hQnin3nh8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from bs4 import BeautifulSoup\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "# Directory with XML files\n",
        "xml_dir = \"/content/drive/MyDrive/dataset2/annotation\"\n",
        "\n",
        "# Get all XML file paths\n",
        "xml_files = [f for f in os.listdir(xml_dir) if f.endswith(\".xml\")]\n",
        "\n",
        "# Extract XML content as raw strings\n",
        "text_targets = []\n",
        "\n",
        "for xml_file in xml_files:\n",
        "    file_path = os.path.join(xml_dir, xml_file)\n",
        "\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "        soup = BeautifulSoup(file, \"xml\")\n",
        "\n",
        "        # Option 1: Keep full XML as text\n",
        "        text_targets.append(str(soup))\n",
        "\n",
        "        # Option 2: If you only want specific tags like onsetSec, pitch, etc.:\n",
        "        # notes = soup.find_all(\"note\")\n",
        "        # extracted = \"\"\n",
        "        # for note in notes:\n",
        "        #     extracted += str(note)  # or customize formatting\n",
        "        # text_targets.append(extracted)\n",
        "  # with open(file_path, 'r') as file:\n",
        "          #  xml_content = file.read()"
      ],
      "metadata": {
        "id": "CEw36nj8nj49"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of XML strings, 1 per file\n",
        "print(text_targets[20][:1500])  # show a snippet of the first\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3b7Kerinlw2",
        "outputId": "3e6b69f3-6439-43ed-e414-9eccd13a3bb9"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
            "<instrumentRecording>\n",
            "<globalParameter>\n",
            "<audioFileName>\\AR_Lick2_FN.wav</audioFileName>\n",
            "<instrument>EGUI</instrument>\n",
            "<instrumentModel>Aristides 010</instrumentModel>\n",
            "<pickUpSetting>unknown</pickUpSetting>\n",
            "<instrumentTuning>40  45  50  55  59  64</instrumentTuning>\n",
            "<recordingDate>13-02-14</recordingDate>\n",
            "<recordingArtist>Christian Kehling</recordingArtist>\n",
            "<instrumentBodyMaterial>unknown</instrumentBodyMaterial>\n",
            "<instrumentStringMaterial>Steel</instrumentStringMaterial>\n",
            "<composer>Christian Kehling</composer>\n",
            "</globalParameter>\n",
            "<transcription>\n",
            "<event>\n",
            "<onsetSec>2.6712</onsetSec>\n",
            "<pitch>56</pitch>\n",
            "<offsetSec>2.9563</offsetSec>\n",
            "<excitationStyle>FS</excitationStyle>\n",
            "<expressionStyle>NO</expressionStyle>\n",
            "<fretNumber>6</fretNumber>\n",
            "<stringNumber>3</stringNumber>\n",
            "<modulationFrequency>0</modulationFrequency>\n",
            "<modulationFrequencyRange>0</modulationFrequencyRange>\n",
            "</event>\n",
            "<event>\n",
            "<onsetSec>2.9723</onsetSec>\n",
            "<pitch>57</pitch>\n",
            "<offsetSec>3.2391</offsetSec>\n",
            "<excitationStyle>FS</excitationStyle>\n",
            "<expressionStyle>NO</expressionStyle>\n",
            "<fretNumber>7</fretNumber>\n",
            "<stringNumber>3</stringNumber>\n",
            "<modulationFrequency>0</modulationFrequency>\n",
            "<modulationFrequencyRange>0</modulationFrequencyRange>\n",
            "</event>\n",
            "<event>\n",
            "<onsetSec>3.2454</onsetSec>\n",
            "<pitch>62</pitch>\n",
            "<offsetSec>3.5123</offsetSec>\n",
            "<excitationStyle>FS</excitationStyle>\n",
            "<expressionStyle>NO</expressionStyle>\n",
            "<fretNumber>7</fretNumber>\n",
            "<stringNumber>4</stringNumber>\n",
            "<modulationFrequency>0</modulationFreque\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Set directories\n",
        "audio_dir = \"/content/drive/MyDrive/dataset2/audio\"\n",
        "xml_dir   = \"/content/drive/MyDrive/dataset2/annotation\"\n",
        "\n",
        "# Storage lists\n",
        "X_audio = []\n",
        "text_targets = []\n",
        "\n",
        "# Build a dict of XML files by basename\n",
        "xml_map = {\n",
        "    os.path.splitext(f)[0]: os.path.join(xml_dir, f)\n",
        "    for f in os.listdir(xml_dir)\n",
        "    if f.lower().endswith(\".xml\")\n",
        "}\n",
        "\n",
        "# Loop through audio files and find matching XML\n",
        "for audio_file in os.listdir(audio_dir):\n",
        "    if audio_file.lower().endswith(\".wav\"):\n",
        "        base_name = os.path.splitext(audio_file)[0]\n",
        "\n",
        "        # Check if XML with same basename exists\n",
        "        if base_name in xml_map:\n",
        "            audio_path = os.path.join(audio_dir, audio_file)\n",
        "            xml_path   = xml_map[base_name]\n",
        "\n",
        "            # -- Process Audio --\n",
        "            y, sr = librosa.load(audio_path, sr=None)\n",
        "            mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=64).T\n",
        "            if mfcc.shape[0] < 2000:\n",
        "                mfcc = np.pad(mfcc, ((0, 2000 - mfcc.shape[0]), (0, 0)), mode='constant')\n",
        "            else:\n",
        "                mfcc = mfcc[:2000, :]\n",
        "            X_audio.append(mfcc)\n",
        "\n",
        "            # -- Process XML --\n",
        "            with open(xml_path, \"r\", encoding=\"utf-8\") as f:\n",
        "                soup = BeautifulSoup(f, \"xml\")\n",
        "                text_targets.append(str(soup))\n",
        "\n",
        "# Convert to numpy\n",
        "X_audio = np.array(X_audio)\n",
        "\n",
        "# Check final stats\n",
        "print(\"✅ Loaded:\")\n",
        "print(f\"  - Audio files: {len(X_audio)}\")\n",
        "print(f\"  - XML targets: {len(text_targets)}\")\n",
        "print(f\"  - Shape of X_audio: {X_audio.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-8BmFk3nrFd",
        "outputId": "a1d4f536-3b90-4cfc-9251-b25402801c6f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded:\n",
            "  - Audio files: 252\n",
            "  - XML targets: 252\n",
            "  - Shape of X_audio: (252, 2000, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for f in os.listdir(audio_dir):\n",
        "  count +=1\n",
        "print(count)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwFM5aYInuVu",
        "outputId": "fba5a7ab-22c7-4954-fe1a-27cd49f30985"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "261\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count =0\n",
        "for xml in os.listdir(xml_dir):\n",
        "  count+=1\n",
        "\n",
        "print(count)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8l2Ji-Ignvqu",
        "outputId": "5191b5fe-ba62-42b8-dc73-6c002761b782"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "261\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ERRor"
      ],
      "metadata": {
        "id": "rEyFLU1Nr7BH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# VOCAB_SIZE = len(tokenizer.word_index) + 1  # +1 for padding\n",
        "VOCAB_SIZE = tokenizer.vocab_size  # This could be 30522 for BERT, etc.\n",
        "VOCAB_SIZE\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kDQzLQVr84X",
        "outputId": "6393b168-80d8-4c0e-8b2b-45b77927a66b"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30522"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Tokenize output (already discussed earlier)\n",
        "Y_token = tokenizer(\n",
        "    text_targets,\n",
        "    return_tensors=\"np\",\n",
        "    padding=\"max_length\",\n",
        "    truncation=True,\n",
        "    max_length=MAX_TARGET_LEN\n",
        ")\n",
        "\n",
        "# Step 2: Prepare decoder inputs and outputs\n",
        "decoder_input_data = Y_token[\"input_ids\"][:, :-1]       # shift left for input\n",
        "decoder_output_data = Y_token[\"input_ids\"][:, 1:]       # shift right for target\n",
        "\n",
        "# Optional: pad so both have same max length\n",
        "decoder_input_data = np.pad(decoder_input_data, ((0,0), (0,1)), constant_values=0)\n",
        "decoder_output_data = np.pad(decoder_output_data, ((0,0), (0,1)), constant_values=0)\n",
        "\n",
        "\n",
        "VOCAB_SIZE = tokenizer.vocab_size  # This could be 30522 for BERT, etc.\n",
        "\n",
        "\n",
        "# Step 3: Build model (your function is good)\n",
        "transformer = build_transformer_model(\n",
        "    audio_seq_len=2000,\n",
        "    audio_feat_dim=64,\n",
        "    max_target_len=MAX_TARGET_LEN,\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    embed_dim= 128,\n",
        "    ff_dim= 256 ,\n",
        "    num_heads= 2 ,\n",
        "    num_layers= 2 ,\n",
        "    dropout_rate=0.1\n",
        ")\n",
        "\n",
        "# Step 4: Compile\n",
        "transformer.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# Step 5: Train\n",
        "transformer.fit(\n",
        "    [X_audio, decoder_input_data],       # 2-input format\n",
        "    decoder_output_data,\n",
        "    batch_size= 4 ,\n",
        "    epochs=20,\n",
        "    validation_split=0.1\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bika68u3nxme",
        "outputId": "5a467a8b-7a59-462d-afeb-8075dabf93ef"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m342s\u001b[0m 5s/step - accuracy: 0.0832 - loss: 9.9540 - val_accuracy: 0.1200 - val_loss: 8.8447\n",
            "Epoch 2/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 5s/step - accuracy: 0.1200 - loss: 8.4791 - val_accuracy: 0.1200 - val_loss: 7.2825\n",
            "Epoch 3/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m325s\u001b[0m 5s/step - accuracy: 0.1200 - loss: 6.9305 - val_accuracy: 0.1200 - val_loss: 5.8463\n",
            "Epoch 4/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m328s\u001b[0m 5s/step - accuracy: 0.1200 - loss: 5.5755 - val_accuracy: 0.1200 - val_loss: 4.8335\n",
            "Epoch 5/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 5s/step - accuracy: 0.1200 - loss: 4.6844 - val_accuracy: 0.1200 - val_loss: 4.2996\n",
            "Epoch 6/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 5s/step - accuracy: 0.1200 - loss: 4.2150 - val_accuracy: 0.1200 - val_loss: 4.0079\n",
            "Epoch 7/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 5s/step - accuracy: 0.1259 - loss: 3.9445 - val_accuracy: 0.1650 - val_loss: 3.7689\n",
            "Epoch 8/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m331s\u001b[0m 5s/step - accuracy: 0.1938 - loss: 3.7041 - val_accuracy: 0.2381 - val_loss: 3.4842\n",
            "Epoch 9/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 5s/step - accuracy: 0.2527 - loss: 3.4078 - val_accuracy: 0.3115 - val_loss: 3.1350\n",
            "Epoch 10/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 5s/step - accuracy: 0.3562 - loss: 3.0466 - val_accuracy: 0.5369 - val_loss: 2.7347\n",
            "Epoch 11/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m273s\u001b[0m 5s/step - accuracy: 0.5749 - loss: 2.6552 - val_accuracy: 0.7169 - val_loss: 2.3303\n",
            "Epoch 12/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m331s\u001b[0m 5s/step - accuracy: 0.7300 - loss: 2.2556 - val_accuracy: 0.7650 - val_loss: 1.9481\n",
            "Epoch 13/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 5s/step - accuracy: 0.7710 - loss: 1.8752 - val_accuracy: 0.7919 - val_loss: 1.6117\n",
            "Epoch 14/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 5s/step - accuracy: 0.7932 - loss: 1.5519 - val_accuracy: 0.8177 - val_loss: 1.3361\n",
            "Epoch 15/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m324s\u001b[0m 5s/step - accuracy: 0.8190 - loss: 1.2828 - val_accuracy: 0.8292 - val_loss: 1.1195\n",
            "Epoch 16/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m285s\u001b[0m 5s/step - accuracy: 0.8469 - loss: 1.0545 - val_accuracy: 0.8419 - val_loss: 0.9516\n",
            "Epoch 17/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 5s/step - accuracy: 0.8839 - loss: 0.8796 - val_accuracy: 0.8558 - val_loss: 0.8204\n",
            "Epoch 18/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 5s/step - accuracy: 0.9088 - loss: 0.7425 - val_accuracy: 0.8581 - val_loss: 0.7151\n",
            "Epoch 19/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 5s/step - accuracy: 0.9134 - loss: 0.6473 - val_accuracy: 0.8746 - val_loss: 0.6268\n",
            "Epoch 20/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m338s\u001b[0m 5s/step - accuracy: 0.9251 - loss: 0.5510 - val_accuracy: 0.8812 - val_loss: 0.5643\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c25d1e31c10>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "✅ Step 1: Save the Full Model\n"
      ],
      "metadata": {
        "id": "N-1Exua9HeUF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save full model (structure + weights + optimizer state)\n",
        "transformer.save('/content/drive/MyDrive/my_audio2xml_model.h5')\n",
        "print(\"✅ Model saved successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJx4hnRXHaw1",
        "outputId": "c4f40373-27fc-4e88-8f55-0ccf3f4e4bc1"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "✅ Step 2: Reload the Model for Inference\n"
      ],
      "metadata": {
        "id": "UQEGRObYILkt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from tensorflow.keras.models import load_model\n",
        "\n",
        "# # Load the model\n",
        "# model = load_model('/content/drive/MyDrive/my_audio2xml_model.h5')\n",
        "# print(\"✅ Model loaded. Ready for inference.\")\n"
      ],
      "metadata": {
        "id": "szNUy8mVHmLr"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "✅ Step 3: Use Model for Testing on Audio\n"
      ],
      "metadata": {
        "id": "awHIWCTeInbN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "def preprocess_audio(file_path):\n",
        "    y, sr = librosa.load(file_path, sr=None)\n",
        "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=64)\n",
        "    mfcc = mfcc.T  # Transpose to shape (time, features)\n",
        "\n",
        "    # Pad or trim to fixed length (2000, 64)\n",
        "    if mfcc.shape[0] > 2000:\n",
        "        mfcc = mfcc[:2000, :]\n",
        "    else:\n",
        "        pad_width = 2000 - mfcc.shape[0]\n",
        "        mfcc = np.pad(mfcc, ((0, pad_width), (0, 0)), mode='constant')\n",
        "\n",
        "    return mfcc[np.newaxis, ...]  # Add batch dimension\n",
        "\n",
        "# Example usage\n",
        "audio_path = '/content/drive/MyDrive/dataset2/audio/AR_A_fret_0-20.wav'\n",
        "input_features = preprocess_audio(audio_path)\n",
        "\n",
        "# Predict\n",
        "output = transformer.predict(input_features)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "TOs-oKJZIO7M",
        "outputId": "28784602-243d-4afd-d06f-bba6deba4355"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Layer \"functional_18\" expects 2 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'data:0' shape=(1, 2000, 64) dtype=float32>]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-1525465781>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/layers/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    161\u001b[0m             \u001b[0;34mf'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;34mf\" but it received {len(inputs)} input tensors. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Layer \"functional_18\" expects 2 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'data:0' shape=(1, 2000, 64) dtype=float32>]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "import librosa\n",
        "\n",
        "# ---------------------------\n",
        "# Step 1: Load the trained model\n",
        "# ---------------------------\n",
        "# model = load_model('/content/drive/MyDrive/my_audio2xml_model.h5')\n",
        "# print(\"✅ Model loaded.\")\n",
        "\n",
        "# ---------------------------\n",
        "# Step 2: Define audio preprocessing function\n",
        "# ---------------------------\n",
        "def preprocess_audio(file_path):\n",
        "    y, sr = librosa.load(file_path, sr=None)\n",
        "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=64)\n",
        "    mfcc = mfcc.T\n",
        "\n",
        "    # Pad or trim to (2000, 64)\n",
        "    if mfcc.shape[0] > 2000:\n",
        "        mfcc = mfcc[:2000, :]\n",
        "    else:\n",
        "        pad_width = 2000 - mfcc.shape[0]\n",
        "        mfcc = np.pad(mfcc, ((0, pad_width), (0, 0)), mode='constant')\n",
        "\n",
        "    return mfcc[np.newaxis, ...]\n",
        "\n",
        "# ---------------------------\n",
        "# Step 3: Load input audio\n",
        "# ---------------------------\n",
        "audio_path = '/content/drive/MyDrive/dataset2/audio/AR_A_fret_0-20.wav'\n",
        "\n",
        "# audio_path = '/content/drive/MyDrive/test_audio.wav'\n",
        "encoder_input = preprocess_audio(audio_path)\n",
        "\n",
        "# ---------------------------\n",
        "# Step 4: Inference loop (greedy decoding)\n",
        "# ---------------------------\n",
        "\n",
        "# Start decoder input (with <start> token — usually 1 or 0 depending on your tokenizer)\n",
        "decoder_input = np.array([[start_token]])  # e.g., np.array([[1]])\n",
        "\n",
        "max_output_length = 50  # set to your max decoder steps\n",
        "decoded_tokens = []\n",
        "\n",
        "for i in range(max_output_length):\n",
        "    predictions = model.predict([encoder_input, decoder_input], verbose=0)\n",
        "    next_token = np.argmax(predictions[:, -1:, :], axis=-1)\n",
        "\n",
        "    # Append the predicted token\n",
        "    decoded_tokens.append(next_token[0, 0])\n",
        "\n",
        "    # Stop if <end> token is reached\n",
        "    if next_token[0, 0] == end_token:\n",
        "        break\n",
        "\n",
        "    # Append next_token to decoder input for next iteration\n",
        "    decoder_input = np.concatenate([decoder_input, next_token], axis=1)\n",
        "\n",
        "# ---------------------------\n",
        "# Step 5: Convert tokens to text (XML/tab)\n",
        "# ---------------------------\n",
        "# Assuming you have a tokenizer or vocabulary reverse mapping:\n",
        "output_text = ''.join([index_to_token[i] for i in decoded_tokens])\n",
        "print(\"Generated Output:\\n\", output_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "id": "73DqXGA_IqIM",
        "outputId": "f5ba9944-df48-4d33-eadd-e046a75ea3f6"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'start_token' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-158188831>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m# Start decoder input (with <start> token — usually 1 or 0 depending on your tokenizer)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mdecoder_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_token\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# e.g., np.array([[1]])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mmax_output_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m  \u001b[0;31m# set to your max decoder steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'start_token' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2Rf19M_DKQXt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}