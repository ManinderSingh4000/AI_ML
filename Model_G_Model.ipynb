{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c150174be5b148bda2f0d75c6ebb37ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_476cefbcfe17477c96e6230785ef9c44",
              "IPY_MODEL_0875f46df9ed4a40a255f5b02afae551",
              "IPY_MODEL_f0325f2475b64cf5a8c8e628f05429e3"
            ],
            "layout": "IPY_MODEL_32f5bd55a3d943d786cc53c5b88d32dc"
          }
        },
        "476cefbcfe17477c96e6230785ef9c44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_489ecb1865614fb2b3934e42ce9029c7",
            "placeholder": "​",
            "style": "IPY_MODEL_bade160139ff4ee4bd80b45a4e39f587",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "0875f46df9ed4a40a255f5b02afae551": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9945bed40f1246008e5d2bbf462ab204",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dd45c9b7bba942b999858adebc558447",
            "value": 48
          }
        },
        "f0325f2475b64cf5a8c8e628f05429e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab059d9d3fd14bc9836aed825dc57cb3",
            "placeholder": "​",
            "style": "IPY_MODEL_df6e37f1bb6d494e8f736f12a4d4d979",
            "value": " 48.0/48.0 [00:00&lt;00:00, 2.60kB/s]"
          }
        },
        "32f5bd55a3d943d786cc53c5b88d32dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "489ecb1865614fb2b3934e42ce9029c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bade160139ff4ee4bd80b45a4e39f587": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9945bed40f1246008e5d2bbf462ab204": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd45c9b7bba942b999858adebc558447": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ab059d9d3fd14bc9836aed825dc57cb3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df6e37f1bb6d494e8f736f12a4d4d979": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3eec4d92bca74f7fb1aed2b4876d3b1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b06e9c33cf924999b8d6e857dd1fbef4",
              "IPY_MODEL_fd486d94daed40a0b817dda398fb2f5e",
              "IPY_MODEL_8651601893a04dd6b9f46f0fac10a2ae"
            ],
            "layout": "IPY_MODEL_2e80c9c11d9d4fdd8e355975dd7d16ba"
          }
        },
        "b06e9c33cf924999b8d6e857dd1fbef4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f44739bbbac4100be429ab1fdfafb72",
            "placeholder": "​",
            "style": "IPY_MODEL_7f6c235799544b8089db6ad194cc7eb4",
            "value": "config.json: 100%"
          }
        },
        "fd486d94daed40a0b817dda398fb2f5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7f9f4cd49ab48b78a981db871dbd686",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_76756d622d7b4658bd0cc49701f0671b",
            "value": 570
          }
        },
        "8651601893a04dd6b9f46f0fac10a2ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2159fb8d11142839f99baa7e8e2c56f",
            "placeholder": "​",
            "style": "IPY_MODEL_4dd03a33885a4c8c982d72cdf372ef9b",
            "value": " 570/570 [00:00&lt;00:00, 68.6kB/s]"
          }
        },
        "2e80c9c11d9d4fdd8e355975dd7d16ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f44739bbbac4100be429ab1fdfafb72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f6c235799544b8089db6ad194cc7eb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a7f9f4cd49ab48b78a981db871dbd686": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76756d622d7b4658bd0cc49701f0671b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a2159fb8d11142839f99baa7e8e2c56f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4dd03a33885a4c8c982d72cdf372ef9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "827d1ef1dfb545c3ae9dd7f713a24d39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7e6a4b8bcea64ca0841ca06e0057a871",
              "IPY_MODEL_70cb4b7c151a4017820bae95a4e9df4e",
              "IPY_MODEL_c3d23e5d4d2040ee8ffdb326a101ddcc"
            ],
            "layout": "IPY_MODEL_cdc43c7f20794d12a6a0dc1d7d8896e8"
          }
        },
        "7e6a4b8bcea64ca0841ca06e0057a871": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9128c14e96943218cd863a56eb3d2f9",
            "placeholder": "​",
            "style": "IPY_MODEL_f6ad696306804342af75c8e02f4b98a4",
            "value": "vocab.txt: 100%"
          }
        },
        "70cb4b7c151a4017820bae95a4e9df4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5af8a6cb3fc14784a7ac9e731e525887",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ca0ebaf5cdd6477eb66c18750103d928",
            "value": 231508
          }
        },
        "c3d23e5d4d2040ee8ffdb326a101ddcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0f5876af0cd48e9ac5206054cc7fd8b",
            "placeholder": "​",
            "style": "IPY_MODEL_36a61b69c0dd472cb276d90b408c0769",
            "value": " 232k/232k [00:00&lt;00:00, 549kB/s]"
          }
        },
        "cdc43c7f20794d12a6a0dc1d7d8896e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9128c14e96943218cd863a56eb3d2f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6ad696306804342af75c8e02f4b98a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5af8a6cb3fc14784a7ac9e731e525887": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca0ebaf5cdd6477eb66c18750103d928": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e0f5876af0cd48e9ac5206054cc7fd8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36a61b69c0dd472cb276d90b408c0769": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef0de7d859964071a4ad347bcd56b056": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b7c987c3445149129b00895ab46e4e60",
              "IPY_MODEL_1408d9b88a374e4c98d263a5531c0704",
              "IPY_MODEL_65b61c9f91614a4eba21922379918f69"
            ],
            "layout": "IPY_MODEL_e8a4cd94bf174b18af8098c202a78868"
          }
        },
        "b7c987c3445149129b00895ab46e4e60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_804fd1081599411080e5554d7ea6c4d0",
            "placeholder": "​",
            "style": "IPY_MODEL_1e1fa25b13a842a8b7fc3971f92475f6",
            "value": "tokenizer.json: 100%"
          }
        },
        "1408d9b88a374e4c98d263a5531c0704": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb642d7f4a65417c88e198a3867c962b",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_45ac6ecc59e94763b5d35a4ce339f3e5",
            "value": 466062
          }
        },
        "65b61c9f91614a4eba21922379918f69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4091e1ae55e24fd2aa47a0e11a73f579",
            "placeholder": "​",
            "style": "IPY_MODEL_da08321e1b8f46448ba1712201c9b330",
            "value": " 466k/466k [00:00&lt;00:00, 2.10MB/s]"
          }
        },
        "e8a4cd94bf174b18af8098c202a78868": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "804fd1081599411080e5554d7ea6c4d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e1fa25b13a842a8b7fc3971f92475f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb642d7f4a65417c88e198a3867c962b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45ac6ecc59e94763b5d35a4ce339f3e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4091e1ae55e24fd2aa47a0e11a73f579": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da08321e1b8f46448ba1712201c9b330": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "🔧 Segment 1: Imports and Basic Configuration\n"
      ],
      "metadata": {
        "id": "ZOf-0w4abxUB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lxml\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYtPFwTZqXVM",
        "outputId": "0dce9520-a9f5-41c5-a6cd-af4ff72a5a06"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (5.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install tensorflow"
      ],
      "metadata": {
        "id": "gHjBhasfoF40"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qCY8Xj7iblBM"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, LayerNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np\n",
        "\n",
        "# Parameters\n",
        "AUDIO_SEQ_LEN = 2000   # from your MFCC/audio features\n",
        "AUDIO_FEATURE_DIM = 64\n",
        "MAX_TARGET_LEN = 100    # token sequence length of XML/tab\n",
        "VOCAB_SIZE = 500        # depends on tokenizer used on target text\n",
        "EMBED_DIM = 256         # transformer model dimensionality\n",
        "NUM_HEADS = 4\n",
        "FF_DIM = 512\n",
        "NUM_LAYERS = 4\n",
        "DROPOUT_RATE = 0.1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "🧠 Segment 2: Transformer Encoder & Decoder Blocks\n"
      ],
      "metadata": {
        "id": "qs5Oizfgb16Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoderBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super().__init__()\n",
        "        self.att = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = tf.keras.Sequential([\n",
        "            Dense(ff_dim, activation=\"relu\"),\n",
        "            Dense(embed_dim),\n",
        "        ])\n",
        "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = Dropout(rate)\n",
        "        self.dropout2 = Dropout(rate)\n",
        "\n",
        "    def call(self, x, training):\n",
        "        attn_output = self.att(x, x)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(x + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "class TransformerDecoderBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super().__init__()\n",
        "        self.att1 = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.att2 = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "\n",
        "        self.ffn = tf.keras.Sequential([\n",
        "            Dense(ff_dim, activation=\"relu\"),\n",
        "            Dense(embed_dim),\n",
        "        ])\n",
        "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm3 = LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = Dropout(rate)\n",
        "        self.dropout2 = Dropout(rate)\n",
        "        self.dropout3 = Dropout(rate)\n",
        "\n",
        "    def call(self, x, enc_output, training, look_ahead_mask=None, padding_mask=None):\n",
        "        attn1 = self.att1(x, x, attention_mask=look_ahead_mask)\n",
        "        attn1 = self.dropout1(attn1, training=training)\n",
        "        out1 = self.layernorm1(x + attn1)\n",
        "\n",
        "        attn2 = self.att2(out1, enc_output)\n",
        "        attn2 = self.dropout2(attn2, training=training)\n",
        "        out2 = self.layernorm2(out1 + attn2)\n",
        "\n",
        "        ffn_output = self.ffn(out2)\n",
        "        ffn_output = self.dropout3(ffn_output, training=training)\n",
        "        return self.layernorm3(out2 + ffn_output)\n"
      ],
      "metadata": {
        "id": "WJif0RUDb0ly"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "📏 Segment 3: Positional Encoding + Token Embedding\n"
      ],
      "metadata": {
        "id": "UcOTGTcEcG1B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "def get_positional_encoding(seq_len, d_model):\n",
        "    pos = np.arange(seq_len)[:, np.newaxis]\n",
        "    i = np.arange(d_model)[np.newaxis, :]\n",
        "    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
        "    angle_rads = pos * angle_rates\n",
        "\n",
        "    # Apply sin to even indices, cos to odd indices\n",
        "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    pos_encoding = angle_rads[np.newaxis, ...]\n",
        "    return tf.cast(pos_encoding, dtype=tf.float32)\n",
        "\n",
        "class PositionalEmbedding(tf.keras.layers.Layer):\n",
        "    def __init__(self, vocab_size, max_len, d_model):\n",
        "        super().__init__()\n",
        "        self.token_embedding = tf.keras.layers.Embedding(vocab_size, d_model)\n",
        "        self.pos_encoding = get_positional_encoding(max_len, d_model)\n",
        "\n",
        "    def call(self, x):\n",
        "        length = tf.shape(x)[1]\n",
        "        x = self.token_embedding(x)\n",
        "        return x + self.pos_encoding[:, :length, :]\n"
      ],
      "metadata": {
        "id": "xZTbUGuNb8gY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "🏗️ Segment 4: Full Transformer Model Assembly\n"
      ],
      "metadata": {
        "id": "-Rf839xQcRyx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_transformer_model(\n",
        "    audio_seq_len=2000,\n",
        "    audio_feat_dim=64,\n",
        "    max_target_len=100,\n",
        "    vocab_size=500,\n",
        "    embed_dim=256,\n",
        "    ff_dim=512,\n",
        "    num_heads=4,\n",
        "    num_layers=4,\n",
        "    dropout_rate=0.1,\n",
        "):\n",
        "    # ==== AUDIO ENCODER ====\n",
        "    encoder_input = Input(shape=(audio_seq_len, audio_feat_dim), name=\"audio_input\")\n",
        "    x = Dense(embed_dim)(encoder_input)  # Project audio features to model dimension\n",
        "    x += get_positional_encoding(audio_seq_len, embed_dim)[:, :audio_seq_len, :]\n",
        "\n",
        "    for _ in range(num_layers):\n",
        "        x = TransformerEncoderBlock(embed_dim, num_heads, ff_dim, dropout_rate)(x, training=True)\n",
        "    encoder_output = x\n",
        "\n",
        "    # ==== TEXT DECODER ====\n",
        "    decoder_input = Input(shape=(max_target_len,), name=\"decoder_input\")  # token ids\n",
        "    y = PositionalEmbedding(vocab_size, max_target_len, embed_dim)(decoder_input)\n",
        "\n",
        "    for _ in range(num_layers):\n",
        "        y = TransformerDecoderBlock(embed_dim, num_heads, ff_dim, dropout_rate)(\n",
        "            y, encoder_output, training=True\n",
        "        )\n",
        "\n",
        "    # Output logits over vocabulary\n",
        "    decoder_output = Dense(vocab_size, activation='softmax')(y)\n",
        "\n",
        "    model = Model(inputs=[encoder_input, decoder_input], outputs=decoder_output)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "r4d_v6kbcK3R"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "✅ Compile the Model"
      ],
      "metadata": {
        "id": "JQm4a7NicYux"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transformer = build_transformer_model()\n",
        "\n",
        "transformer.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n"
      ],
      "metadata": {
        "id": "sOk936-AcUbg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 737
        },
        "id": "BINyQKCecbwB",
        "outputId": "e89ea5fe-671a-475f-f906-72ec896e7262"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_8\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_8\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ audio_input (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │         \u001b[38;5;34m16,640\u001b[0m │ audio_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add (\u001b[38;5;33mAdd\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ transformer_encoder_block │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │      \u001b[38;5;34m1,315,840\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
              "│ (\u001b[38;5;33mTransformerEncoderBlock\u001b[0m) │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ transformer_encoder_bloc… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │      \u001b[38;5;34m1,315,840\u001b[0m │ transformer_encoder_b… │\n",
              "│ (\u001b[38;5;33mTransformerEncoderBlock\u001b[0m) │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ decoder_input             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ transformer_encoder_bloc… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │      \u001b[38;5;34m1,315,840\u001b[0m │ transformer_encoder_b… │\n",
              "│ (\u001b[38;5;33mTransformerEncoderBlock\u001b[0m) │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ positional_embedding      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │        \u001b[38;5;34m128,000\u001b[0m │ decoder_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mPositionalEmbedding\u001b[0m)     │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ transformer_encoder_bloc… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │      \u001b[38;5;34m1,315,840\u001b[0m │ transformer_encoder_b… │\n",
              "│ (\u001b[38;5;33mTransformerEncoderBlock\u001b[0m) │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ transformer_decoder_block │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m2,368,256\u001b[0m │ positional_embedding[\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mTransformerDecoderBlock\u001b[0m) │                        │                │ transformer_encoder_b… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ transformer_decoder_bloc… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m2,368,256\u001b[0m │ transformer_decoder_b… │\n",
              "│ (\u001b[38;5;33mTransformerDecoderBlock\u001b[0m) │                        │                │ transformer_encoder_b… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ transformer_decoder_bloc… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m2,368,256\u001b[0m │ transformer_decoder_b… │\n",
              "│ (\u001b[38;5;33mTransformerDecoderBlock\u001b[0m) │                        │                │ transformer_encoder_b… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ transformer_decoder_bloc… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m2,368,256\u001b[0m │ transformer_decoder_b… │\n",
              "│ (\u001b[38;5;33mTransformerDecoderBlock\u001b[0m) │                        │                │ transformer_encoder_b… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m500\u001b[0m)       │        \u001b[38;5;34m128,500\u001b[0m │ transformer_decoder_b… │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ audio_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> │ audio_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ transformer_encoder_block │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,315,840</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoderBlock</span>) │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ transformer_encoder_bloc… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,315,840</span> │ transformer_encoder_b… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoderBlock</span>) │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ decoder_input             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ transformer_encoder_bloc… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,315,840</span> │ transformer_encoder_b… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoderBlock</span>) │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ positional_embedding      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128,000</span> │ decoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbedding</span>)     │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ transformer_encoder_bloc… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,315,840</span> │ transformer_encoder_b… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoderBlock</span>) │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ transformer_decoder_block │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,368,256</span> │ positional_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoderBlock</span>) │                        │                │ transformer_encoder_b… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ transformer_decoder_bloc… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,368,256</span> │ transformer_decoder_b… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoderBlock</span>) │                        │                │ transformer_encoder_b… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ transformer_decoder_bloc… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,368,256</span> │ transformer_decoder_b… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoderBlock</span>) │                        │                │ transformer_encoder_b… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ transformer_decoder_bloc… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,368,256</span> │ transformer_decoder_b… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoderBlock</span>) │                        │                │ transformer_encoder_b… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128,500</span> │ transformer_decoder_b… │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m15,009,524\u001b[0m (57.26 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,009,524</span> (57.26 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m15,009,524\u001b[0m (57.26 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,009,524</span> (57.26 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "🧪 Segment 5: Training Loop with Teacher Forcing\n",
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "U4hs8JUucmF5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔄 Step 1: Prepare Training Data\n"
      ],
      "metadata": {
        "id": "Rj6VDiJ9cyQp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_decoder_inputs_outputs(tokenized_targets, start_token_id):\n",
        "    \"\"\"\n",
        "    Takes target sequences (e.g., [34, 76, 12, 9, ...]) and returns:\n",
        "    decoder_input: [<start>, 34, 76, 12, ...]\n",
        "    decoder_output: [34, 76, 12, 9, ...]\n",
        "    \"\"\"\n",
        "    decoder_inputs = []\n",
        "    decoder_outputs = []\n",
        "\n",
        "    for seq in tokenized_targets:\n",
        "        decoder_inputs.append([start_token_id] + seq[:-1])\n",
        "        decoder_outputs.append(seq)\n",
        "\n",
        "    return np.array(decoder_inputs), np.array(decoder_outputs)\n"
      ],
      "metadata": {
        "id": "WZP6kanRcgLx"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "🧾 🔠 Segment 5.1: Tokenize XML or Tablature Targets"
      ],
      "metadata": {
        "id": "CnOMENAhdanh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "🧾 Step 1: Tokenize Output Text (XML or Tablature)\n"
      ],
      "metadata": {
        "id": "Z0DFng2neIWK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "\n",
        "# Assume you have a list of string targets (e.g., XML or tablature format)\n",
        "# Example:\n",
        "text_targets = [\n",
        "    \"<note><onsetSec>6.605</onsetSec></note>\",\n",
        "    \"<note><onsetSec>7.230</onsetSec></note>\",\n",
        "    \"E|--0--2--3--|\",\n",
        "    # etc.\n",
        "]\n",
        "\n",
        "# Use character-level tokenizer (or switch to word-level if preferred)\n",
        "tokenizer = Tokenizer(char_level=True, filters='', lower=False)\n",
        "tokenizer.fit_on_texts(text_targets)\n",
        "\n",
        "# Convert each string to a list of token IDs\n",
        "Y_token = tokenizer.texts_to_sequences(text_targets)\n",
        "\n",
        "# Set a maximum length for output sequences\n",
        "MAX_TARGET_LEN = 100\n",
        "Y_token = pad_sequences(Y_token, maxlen=MAX_TARGET_LEN, padding='post')\n",
        "\n",
        "# Update vocabulary size\n",
        "VOCAB_SIZE = len(tokenizer.word_index) + 1\n",
        "start_token_id = tokenizer.word_index.get('<', 1)  # use `<` as start token\n"
      ],
      "metadata": {
        "id": "YQ7dudxGd_6C"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔁 Step 2: Prepare Decoder Input and Target Output\n"
      ],
      "metadata": {
        "id": "PxRaOGJkeGFy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_decoder_inputs_outputs(tokenized_targets, start_token_id):\n",
        "    decoder_inputs = []\n",
        "    decoder_outputs = []\n",
        "\n",
        "    for seq in tokenized_targets:\n",
        "        decoder_input = [start_token_id] + list(seq[:-1])  # shift right\n",
        "        decoder_output = list(seq)\n",
        "        decoder_inputs.append(decoder_input)\n",
        "        decoder_outputs.append(decoder_output)\n",
        "\n",
        "    return np.array(decoder_inputs), np.array(decoder_outputs)\n",
        "\n",
        "# Apply function\n",
        "decoder_input_data, decoder_output_data = prepare_decoder_inputs_outputs(Y_token, start_token_id)\n",
        "\n",
        "# decoder_output needs to be 3D for sparse_categorical_crossentropy\n",
        "decoder_output_data = decoder_output_data[..., np.newaxis]\n"
      ],
      "metadata": {
        "id": "NocSv0WceB4x"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare The Audio Files\n"
      ],
      "metadata": {
        "id": "uKL5O5xGeioh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "# Directory containing your .wav files\n",
        "audio_dir = \"/content/drive/MyDrive/dataset2/audio\"  # change as needed\n",
        "files = [f for f in os.listdir(audio_dir) if f.endswith(\".wav\")]\n",
        "\n",
        "# Parameters\n",
        "MAX_AUDIO_LEN = 2000  # pad/truncate to 2000 time steps\n",
        "N_MFCC = 64           # number of MFCCs to extract\n",
        "\n",
        "def extract_mfcc(file_path, max_len=MAX_AUDIO_LEN, n_mfcc=N_MFCC):\n",
        "    y, sr = librosa.load(file_path, sr=None)\n",
        "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
        "    mfcc = mfcc.T  # shape: (time, 64)\n",
        "\n",
        "    if mfcc.shape[0] < max_len:\n",
        "        # Pad with zeros if shorter\n",
        "        pad_width = max_len - mfcc.shape[0]\n",
        "        mfcc = np.pad(mfcc, ((0, pad_width), (0, 0)), mode='constant')\n",
        "    else:\n",
        "        # Truncate if longer\n",
        "        mfcc = mfcc[:max_len, :]\n",
        "\n",
        "    return mfcc\n",
        "\n",
        "# Load all MFCCs\n",
        "X_audio = []\n",
        "for fname in files:\n",
        "    path = os.path.join(audio_dir, fname)\n",
        "    mfcc = extract_mfcc(path)\n",
        "    X_audio.append(mfcc)\n",
        "\n",
        "X_audio = np.array(X_audio)  # final shape: (N, 2000, 64)\n"
      ],
      "metadata": {
        "id": "xBUDZ291eM-i"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_audio[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJiYuqjGpZxW",
        "outputId": "99c3c027-6c81-4a47-95b6-58775192daf6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-6.8336926e+02  4.3504944e+01  3.3611908e+01 ... -4.6937406e-01\n",
            "   6.4101839e-01  9.3179834e-01]\n",
            " [-6.7360248e+02  5.5079887e+01  4.1050835e+01 ... -6.6569102e-01\n",
            "   2.8163908e+00  4.1774211e+00]\n",
            " [-6.6940997e+02  6.0271637e+01  4.5435455e+01 ...  2.8687230e-01\n",
            "   3.8351529e+00  4.8378811e+00]\n",
            " ...\n",
            " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ...  0.0000000e+00\n",
            "   0.0000000e+00  0.0000000e+00]\n",
            " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ...  0.0000000e+00\n",
            "   0.0000000e+00  0.0000000e+00]\n",
            " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ...  0.0000000e+00\n",
            "   0.0000000e+00  0.0000000e+00]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "####"
      ],
      "metadata": {
        "id": "3JQjPQnopZuU"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Paths to folders\n",
        "audio_dir = \"/content/drive/MyDrive/dataset2/audio\"\n",
        "xml_dir   = \"/content/drive/MyDrive/dataset2/annotation\"\n",
        "\n",
        "X_audio = []\n",
        "text_targets = []\n",
        "\n",
        "# Step 1: Create a set of XML base names\n",
        "xml_files = {os.path.splitext(f)[0] for f in os.listdir(xml_dir) if f.endswith(\".xml\")}\n",
        "\n",
        "# Step 2: Iterate audio files and only include those with matching XML\n",
        "for audio_file in os.listdir(audio_dir):\n",
        "    if audio_file.endswith(\".wav\"):\n",
        "        base_name = os.path.splitext(audio_file)[0]\n",
        "\n",
        "        if base_name in xml_files:\n",
        "            audio_path = os.path.join(audio_dir, audio_file)\n",
        "            xml_path   = os.path.join(xml_dir, base_name + \".xml\")\n",
        "\n",
        "            # --- Process audio ---\n",
        "            y, sr = librosa.load(audio_path, sr=None)\n",
        "            mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=64).T\n",
        "            if mfcc.shape[0] < 2000:\n",
        "                mfcc = np.pad(mfcc, ((0, 2000 - mfcc.shape[0]), (0, 0)), mode='constant')\n",
        "            else:\n",
        "                mfcc = mfcc[:2000, :]\n",
        "            X_audio.append(mfcc)\n",
        "\n",
        "            # --- Process XML ---\n",
        "            with open(xml_path, \"r\", encoding=\"utf-8\") as f:\n",
        "                soup = BeautifulSoup(f, \"xml\")\n",
        "                text_targets.append(str(soup))\n",
        "\n",
        "# Convert to array\n",
        "X_audio = np.array(X_audio)\n",
        "\n",
        "# Final sanity check\n",
        "print(\"✅ Matching files loaded:\")\n",
        "print(f\" - Audio files: {len(X_audio)}\")\n",
        "print(f\" - XML targets: {len(text_targets)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVHgx4yuqELU",
        "outputId": "47c1a8ff-1cf6-4f3d-86fd-f5cf22f5f5c9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Matching files loaded:\n",
            " - Audio files: 657\n",
            " - XML targets: 657\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "####"
      ],
      "metadata": {
        "id": "XTHCgbFnl8_7"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_audio)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXfJAz_ne2NR",
        "outputId": "5b62a0cc-48ac-4ef5-fc1a-3db58d97af9a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "657"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Load pre-trained tokenizer (can use T5, BERT, GPT2, etc.)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# Optional: Clean up any empty or malformed XML\n",
        "text_targets = [txt.strip() for txt in text_targets if txt and len(txt.strip()) > 0]\n",
        "\n",
        "# Critical: Match count of inputs and outputs\n",
        "assert len(text_targets) == len(X_audio), f\"Mismatch: {len(text_targets)} targets vs {len(X_audio)} audio\"\n",
        "\n",
        "# Tokenize all XMLs into input_ids\n",
        "Y_token = tokenizer(\n",
        "    text_targets,\n",
        "    return_tensors=\"np\",      # for NumPy (since X_audio is a NumPy array)\n",
        "    padding=\"max_length\",\n",
        "    truncation=True,\n",
        "    max_length=512            # or whatever your Transformer model expects\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269,
          "referenced_widgets": [
            "c150174be5b148bda2f0d75c6ebb37ce",
            "476cefbcfe17477c96e6230785ef9c44",
            "0875f46df9ed4a40a255f5b02afae551",
            "f0325f2475b64cf5a8c8e628f05429e3",
            "32f5bd55a3d943d786cc53c5b88d32dc",
            "489ecb1865614fb2b3934e42ce9029c7",
            "bade160139ff4ee4bd80b45a4e39f587",
            "9945bed40f1246008e5d2bbf462ab204",
            "dd45c9b7bba942b999858adebc558447",
            "ab059d9d3fd14bc9836aed825dc57cb3",
            "df6e37f1bb6d494e8f736f12a4d4d979",
            "3eec4d92bca74f7fb1aed2b4876d3b1f",
            "b06e9c33cf924999b8d6e857dd1fbef4",
            "fd486d94daed40a0b817dda398fb2f5e",
            "8651601893a04dd6b9f46f0fac10a2ae",
            "2e80c9c11d9d4fdd8e355975dd7d16ba",
            "0f44739bbbac4100be429ab1fdfafb72",
            "7f6c235799544b8089db6ad194cc7eb4",
            "a7f9f4cd49ab48b78a981db871dbd686",
            "76756d622d7b4658bd0cc49701f0671b",
            "a2159fb8d11142839f99baa7e8e2c56f",
            "4dd03a33885a4c8c982d72cdf372ef9b",
            "827d1ef1dfb545c3ae9dd7f713a24d39",
            "7e6a4b8bcea64ca0841ca06e0057a871",
            "70cb4b7c151a4017820bae95a4e9df4e",
            "c3d23e5d4d2040ee8ffdb326a101ddcc",
            "cdc43c7f20794d12a6a0dc1d7d8896e8",
            "c9128c14e96943218cd863a56eb3d2f9",
            "f6ad696306804342af75c8e02f4b98a4",
            "5af8a6cb3fc14784a7ac9e731e525887",
            "ca0ebaf5cdd6477eb66c18750103d928",
            "e0f5876af0cd48e9ac5206054cc7fd8b",
            "36a61b69c0dd472cb276d90b408c0769",
            "ef0de7d859964071a4ad347bcd56b056",
            "b7c987c3445149129b00895ab46e4e60",
            "1408d9b88a374e4c98d263a5531c0704",
            "65b61c9f91614a4eba21922379918f69",
            "e8a4cd94bf174b18af8098c202a78868",
            "804fd1081599411080e5554d7ea6c4d0",
            "1e1fa25b13a842a8b7fc3971f92475f6",
            "cb642d7f4a65417c88e198a3867c962b",
            "45ac6ecc59e94763b5d35a4ce339f3e5",
            "4091e1ae55e24fd2aa47a0e11a73f579",
            "da08321e1b8f46448ba1712201c9b330"
          ]
        },
        "id": "2UI8GXCNl-rz",
        "outputId": "0c7ef059-ace2-4e87-cb21-5a169f050af8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c150174be5b148bda2f0d75c6ebb37ce"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3eec4d92bca74f7fb1aed2b4876d3b1f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "827d1ef1dfb545c3ae9dd7f713a24d39"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ef0de7d859964071a4ad347bcd56b056"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "✅ Step 1: Parse XML Files\n"
      ],
      "metadata": {
        "id": "u2kI81BDfDub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from bs4 import BeautifulSoup\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "# Directory with XML files\n",
        "xml_dir = \"/content/drive/MyDrive/dataset2/annotation\"\n",
        "\n",
        "# Get all XML file paths\n",
        "xml_files = [f for f in os.listdir(xml_dir) if f.endswith(\".xml\")]\n",
        "\n",
        "# # Extract XML content as raw strings\n",
        "\n",
        "\n",
        "\n",
        "# text_targets = []\n",
        "\n",
        "# for xml_file in xml_files:\n",
        "#     file_path = os.path.join(xml_dir, xml_file)\n",
        "\n",
        "#     with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "#       xml_content = file.read()\n",
        "#       print(xml_content)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # soup = BeautifulSoup(file, \"xml\")\n",
        "\n",
        "        # # Option 1: Keep full XML as text\n",
        "        # text_targets.append(str(soup))\n",
        "\n",
        "        # Option 2: If you only want specific tags like onsetSec, pitch, etc.:\n",
        "        # notes = soup.find_all(\"note\")\n",
        "        # extracted = \"\"\n",
        "        # for note in notes:\n",
        "        #     extracted += str(note)  # or customize formatting\n",
        "        # text_targets.append(extracted)\n",
        "  # with open(file_path, 'r') as file:\n",
        "          #  xml_content = file.read()"
      ],
      "metadata": {
        "id": "LTmhzo0nvkYN"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Supplementry Code"
      ],
      "metadata": {
        "id": "Zt1GSxD8vlj3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from bs4 import BeautifulSoup\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "# Directory with XML files\n",
        "xml_dir = \"/content/drive/MyDrive/dataset2/annotation\"\n",
        "\n",
        "# Get all XML file paths\n",
        "xml_files = [f for f in os.listdir(xml_dir) if f.endswith(\".xml\")]\n",
        "\n",
        "# Extract XML content as raw strings\n",
        "text_targets = []\n",
        "\n",
        "for xml_file in xml_files:\n",
        "    file_path = os.path.join(xml_dir, xml_file)\n",
        "\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "        soup = BeautifulSoup(file, \"xml\")\n",
        "\n",
        "        # Option 1: Keep full XML as text\n",
        "        text_targets.append(str(soup))\n",
        "\n",
        "        # Option 2: If you only want specific tags like onsetSec, pitch, etc.:\n",
        "        # notes = soup.find_all(\"note\")\n",
        "        # extracted = \"\"\n",
        "        # for note in notes:\n",
        "        #     extracted += str(note)  # or customize formatting\n",
        "        # text_targets.append(extracted)\n",
        "  # with open(file_path, 'r') as file:\n",
        "          #  xml_content = file.read()"
      ],
      "metadata": {
        "id": "LVrg5Moxe4hx"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of XML strings, 1 per file\n",
        "print(text_targets[20][:600])  # show a snippet of the first\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SvwWOdHfP06",
        "outputId": "0c494af9-211f-4789-d5b4-327ffeffea6b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
            "<instrumentRecording>\n",
            "<globalParameter>\n",
            "<audioFileName>G53-51111-1111-00012.wav</audioFileName>\n",
            "<instrument>EGUI</instrument>\n",
            "<recordingDate>07.01.2013</recordingDate>\n",
            "</globalParameter>\n",
            "<transcription>\n",
            "<event>\n",
            "<pitch>51</pitch>\n",
            "<onsetSec>0.2</onsetSec>\n",
            "<offsetSec>2.5</offsetSec>\n",
            "<fretNumber>11</fretNumber>\n",
            "<stringNumber>1</stringNumber>\n",
            "<excitationStyle>PK</excitationStyle>\n",
            "<expressionStyle>NO</expressionStyle>\n",
            "</event>\n",
            "</transcription>\n",
            "</instrumentRecording>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "✅ Step 2: Match with Audio\n"
      ],
      "metadata": {
        "id": "KmfS33TBfR70"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Set directories\n",
        "audio_dir = \"/content/drive/MyDrive/dataset2/audio\"\n",
        "xml_dir   = \"/content/drive/MyDrive/dataset2/annotation\"\n",
        "\n",
        "# Storage lists\n",
        "X_audio = []\n",
        "text_targets = []\n",
        "\n",
        "# Build a dict of XML files by basename\n",
        "xml_map = {\n",
        "    os.path.splitext(f)[0]: os.path.join(xml_dir, f)\n",
        "    for f in os.listdir(xml_dir)\n",
        "    if f.lower().endswith(\".xml\")\n",
        "}\n",
        "\n",
        "# Loop through audio files and find matching XML\n",
        "for audio_file in os.listdir(audio_dir):\n",
        "    if audio_file.lower().endswith(\".wav\"):\n",
        "        base_name = os.path.splitext(audio_file)[0]\n",
        "\n",
        "        # Check if XML with same basename exists\n",
        "        if base_name in xml_map:\n",
        "            audio_path = os.path.join(audio_dir, audio_file)\n",
        "            xml_path   = xml_map[base_name]\n",
        "\n",
        "            # -- Process Audio --\n",
        "            y, sr = librosa.load(audio_path, sr=None)\n",
        "            mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=64).T\n",
        "            if mfcc.shape[0] < 2000:\n",
        "                mfcc = np.pad(mfcc, ((0, 2000 - mfcc.shape[0]), (0, 0)), mode='constant')\n",
        "            else:\n",
        "                mfcc = mfcc[:2000, :]\n",
        "            X_audio.append(mfcc)\n",
        "\n",
        "            # -- Process XML --\n",
        "            with open(xml_path, \"r\", encoding=\"utf-8\") as f:\n",
        "                soup = BeautifulSoup(f, \"xml\")\n",
        "                text_targets.append(str(soup))\n",
        "\n",
        "# Convert to numpy\n",
        "X_audio = np.array(X_audio)\n",
        "\n",
        "# Check final stats\n",
        "print(\"✅ Loaded:\")\n",
        "print(f\"  - Audio files: {len(X_audio)}\")\n",
        "print(f\"  - XML targets: {len(text_targets)}\")\n",
        "print(f\"  - Shape of X_audio: {X_audio.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjUaEYP7fScB",
        "outputId": "7305d5db-9877-49f3-cf6f-ad7a6b3942f1"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded:\n",
            "  - Audio files: 657\n",
            "  - XML targets: 657\n",
            "  - Shape of X_audio: (657, 2000, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# text_targets\n",
        "# X_audio"
      ],
      "metadata": {
        "id": "EOD1nLDAfz5q"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "🚀 Step 4: Train the Transformer Model\n"
      ],
      "metadata": {
        "id": "qpg4Za1tfmqK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print(os.listdir(xml_dir))\n"
      ],
      "metadata": {
        "id": "NdVmasAJfnlB"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for f in os.listdir(audio_dir):\n",
        "  count +=1\n",
        "print(count)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yt6E95dTg5ax",
        "outputId": "e4242cd0-5993-4275-be84-d6497a70de3e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count =0\n",
        "for xml in os.listdir(xml_dir):\n",
        "  count+=1\n",
        "\n",
        "print(count)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7S6t7zYWhTCi",
        "outputId": "5d395900-2d48-429b-f133-318f64ae5404"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "🚀 Step 4: Train the Transformer Model\n"
      ],
      "metadata": {
        "id": "1WBmGY5njvsz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Tokenize output (already discussed earlier)\n",
        "Y_token = tokenizer(\n",
        "    text_targets,\n",
        "    return_tensors=\"np\",\n",
        "    padding=\"max_length\",\n",
        "    truncation=True,\n",
        "    max_length=MAX_TARGET_LEN\n",
        ")\n",
        "\n",
        "# Step 2: Prepare decoder inputs and outputs\n",
        "decoder_input_data = Y_token[\"input_ids\"][:, :-1]       # shift left for input\n",
        "decoder_output_data = Y_token[\"input_ids\"][:, 1:]       # shift right for target\n",
        "\n",
        "# Optional: pad so both have same max length\n",
        "decoder_input_data = np.pad(decoder_input_data, ((0,0), (0,1)), constant_values=0)\n",
        "decoder_output_data = np.pad(decoder_output_data, ((0,0), (0,1)), constant_values=0)\n",
        "\n",
        "# Step 3: Build model (your function is good)\n",
        "transformer = build_transformer_model(\n",
        "    audio_seq_len=2000,\n",
        "    audio_feat_dim=64,\n",
        "    max_target_len=MAX_TARGET_LEN,\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    embed_dim= 128,\n",
        "    ff_dim= 256 ,\n",
        "    num_heads= 2 ,\n",
        "    num_layers= 2 ,\n",
        "    dropout_rate=0.1\n",
        ")\n",
        "\n",
        "# Step 4: Compile\n",
        "transformer.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# Step 5: Train\n",
        "transformer.fit(\n",
        "    [X_audio, decoder_input_data],       # 2-input format\n",
        "    decoder_output_data,\n",
        "    batch_size= 4 ,\n",
        "    epochs=20,\n",
        "    validation_split=0.1\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "391C7tEoi_JC",
        "outputId": "afeda81d-5831-4885-86bb-4986981421a9"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 259ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
            "Epoch 2/20\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 52ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
            "Epoch 3/20\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 54ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
            "Epoch 4/20\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 53ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
            "Epoch 5/20\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 51ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
            "Epoch 6/20\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 52ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
            "Epoch 7/20\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 51ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
            "Epoch 8/20\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 52ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
            "Epoch 9/20\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 52ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
            "Epoch 10/20\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 54ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
            "Epoch 11/20\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 52ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
            "Epoch 12/20\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 53ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
            "Epoch 13/20\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 57ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
            "Epoch 14/20\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 58ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
            "Epoch 15/20\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 58ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
            "Epoch 16/20\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 59ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
            "Epoch 17/20\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 62ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
            "Epoch 18/20\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 62ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
            "Epoch 19/20\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
            "Epoch 20/20\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 61ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7cfae010de10>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "✅ 3. Check for any NaNs in your data:\n"
      ],
      "metadata": {
        "id": "40Cy1nSu6Icn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.isnan(X_audio).any()\n",
        "# np.isnan(decoder_input_data).any()\n",
        "# np.isnan(decoder_output_data).any()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbi_fxBE6IA_",
        "outputId": "fbc70af7-f805-4fbc-849c-6944fb40c242"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.decode(decoder_output_data[0]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCBVBO0I6ao2",
        "outputId": "443ef048-25c6-4a19-afbb-e90c8fa2cb58"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<? xml version = \" 1. 0 \" encoding = \" utf - 8 \"? > < instrumentrecording > < globalparameter > < audiofilename > g53 - 44104 - 1111 - 00005. wav < / audiofilename > < instrument > egui < / instrument > < recordingdate > 07. 01. 2013 < / recordingdate > < / globalparameter > < transcription > < event > < pitch > [SEP] [PAD]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Testing Time"
      ],
      "metadata": {
        "id": "u3H4ZZfT1tn1"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_test_audio(path, max_len=2000):\n",
        "    y, sr = librosa.load(path, sr=None)\n",
        "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=64).T\n",
        "\n",
        "    if mfcc.shape[0] < max_len:\n",
        "        mfcc = np.pad(mfcc, ((0, max_len - mfcc.shape[0]), (0, 0)), mode='constant')\n",
        "    else:\n",
        "        mfcc = mfcc[:max_len, :]\n",
        "\n",
        "    return np.expand_dims(mfcc, axis=0)  # shape: (1, max_len, 64)\n",
        "\n",
        "# Example:\n",
        "test_audio_path = \"/content/drive/MyDrive/dataset2/audio/1-E1-Major 00 (1).wav\"\n",
        "test_audio = preprocess_test_audio(test_audio_path)\n"
      ],
      "metadata": {
        "id": "oI4H9E7K1tjt"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def greedy_decode(transformer, audio_input, tokenizer, max_len=256, start_token_id=101, end_token_id=102):\n",
        "    decoded_ids = [start_token_id]\n",
        "\n",
        "    for _ in range(max_len):\n",
        "        decoder_input = np.array(decoded_ids)[None, :]  # (1, seq_len)\n",
        "        preds = transformer.predict([audio_input, decoder_input], verbose=0)\n",
        "\n",
        "        next_id = np.argmax(preds[0, -1, :])  # Take last time-step's highest prob token\n",
        "\n",
        "        if next_id == end_token_id:\n",
        "            break\n",
        "\n",
        "        decoded_ids.append(next_id)\n",
        "\n",
        "    return decoded_ids\n"
      ],
      "metadata": {
        "id": "EJNztpVq5c6e"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define tokenizer special token IDs\n",
        "start_token = tokenizer.cls_token_id or 101\n",
        "end_token   = tokenizer.sep_token_id or 102\n",
        "\n",
        "# Run decoding\n",
        "output_token_ids = greedy_decode(transformer, test_audio, tokenizer, max_len=256,\n",
        "                                 start_token_id=start_token, end_token_id=end_token)\n",
        "\n",
        "# Convert back to XML string\n",
        "predicted_text = tokenizer.decode(output_token_ids, skip_special_tokens=True)\n",
        "\n",
        "# Display\n",
        "print(\"🔍 Predicted Output:\\n\", predicted_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "dpWuELWm5e4G",
        "outputId": "b73bf4de-5aeb-47f7-8947-84672a238c38"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "Graph execution error:\n\nDetected at node functional_13_1/positional_embedding_1_1/add defined at (most recent call last):\n<stack traces unavailable>\nIncompatible shapes: [1,101,128] vs. [1,100,128]\n\t [[{{node functional_13_1/positional_embedding_1_1/add}}]]\n\ttf2xla conversion failed while converting __inference_one_step_on_data_71655[]. Run with TF_DUMP_GRAPH_PREFIX=/path/to/dump/dir and --vmodule=xla_compiler=2 to obtain a dump of the compiled functions.\n\t [[StatefulPartitionedCall]] [Op:__inference_one_step_on_data_distributed_71840]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-4bde2069a36d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Run decoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m output_token_ids = greedy_decode(transformer, test_audio, tokenizer, max_len=256,\n\u001b[0m\u001b[1;32m      7\u001b[0m                                  start_token_id=start_token, end_token_id=end_token)\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-37-56ad06bf12c8>\u001b[0m in \u001b[0;36mgreedy_decode\u001b[0;34m(transformer, audio_input, tokenizer, max_len, start_token_id, end_token_id)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mdecoder_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoded_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# (1, seq_len)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maudio_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_input\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mnext_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Take last time-step's highest prob token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m       \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0mkeras_symbolic_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m_is_keras_symbolic_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkeras_symbolic_tensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node functional_13_1/positional_embedding_1_1/add defined at (most recent call last):\n<stack traces unavailable>\nIncompatible shapes: [1,101,128] vs. [1,100,128]\n\t [[{{node functional_13_1/positional_embedding_1_1/add}}]]\n\ttf2xla conversion failed while converting __inference_one_step_on_data_71655[]. Run with TF_DUMP_GRAPH_PREFIX=/path/to/dump/dir and --vmodule=xla_compiler=2 to obtain a dump of the compiled functions.\n\t [[StatefulPartitionedCall]] [Op:__inference_one_step_on_data_distributed_71840]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Error Here\n"
      ],
      "metadata": {
        "id": "Kb0ZBckMAHLQ"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_positional_encoding(seq_len, d_model):\n",
        "    pos = np.arange(seq_len)[:, np.newaxis]\n",
        "    i = np.arange(d_model)[np.newaxis, :]\n",
        "    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
        "    angle_rads = pos * angle_rates\n",
        "\n",
        "    sines = np.sin(angle_rads[:, 0::2])\n",
        "    cosines = np.cos(angle_rads[:, 1::2])\n",
        "    pos_encoding = np.concatenate([sines, cosines], axis=-1)\n",
        "    pos_encoding = pos_encoding[np.newaxis, ...]  # shape (1, seq_len, d_model)\n",
        "\n",
        "    return tf.cast(pos_encoding, dtype=tf.float32)\n"
      ],
      "metadata": {
        "id": "MBrUPIjZ7e4X"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DynamicPositionalEmbedding(tf.keras.layers.Layer):\n",
        "    def __init__(self, embed_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "    def call(self, x):\n",
        "        seq_len = tf.shape(x)[1]\n",
        "        pos_encoding = get_positional_encoding(seq_len, self.embed_dim)\n",
        "        return x + pos_encoding\n"
      ],
      "metadata": {
        "id": "xRYHdkpyAGGI"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Embedding, Dense, LayerNormalization, Dropout, MultiHeadAttention, Add\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Define Transformer block\n",
        "def transformer_block(inputs, embed_dim, num_heads, ff_dim, dropout_rate=0.1):\n",
        "    attention_output = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)(inputs, inputs)\n",
        "    attention_output = Dropout(dropout_rate)(attention_output)\n",
        "    out1 = LayerNormalization(epsilon=1e-6)(inputs + attention_output)\n",
        "\n",
        "    ffn_output = Dense(ff_dim, activation='relu')(out1)\n",
        "    ffn_output = Dense(embed_dim)(ffn_output)\n",
        "    ffn_output = Dropout(dropout_rate)(ffn_output)\n",
        "    return LayerNormalization(epsilon=1e-6)(out1 + ffn_output)\n",
        "\n",
        "# Full Transformer model\n",
        "def build_transformer_model(audio_seq_len, audio_feat_dim, max_target_len,\n",
        "                            vocab_size, embed_dim, ff_dim, num_heads, num_layers, dropout_rate=0.1):\n",
        "    # Encoder\n",
        "    encoder_input = Input(shape=(audio_seq_len, audio_feat_dim), name=\"encoder_input\")\n",
        "    x_enc = Dense(embed_dim)(encoder_input)\n",
        "    for _ in range(num_layers):\n",
        "        x_enc = transformer_block(x_enc, embed_dim, num_heads, ff_dim, dropout_rate)\n",
        "\n",
        "    # Decoder\n",
        "    decoder_input = Input(shape=(None,), name=\"decoder_input\")\n",
        "    x_dec = Embedding(input_dim=vocab_size, output_dim=embed_dim)(decoder_input)\n",
        "    x_dec = DynamicPositionalEmbedding(embed_dim)(x_dec)\n",
        "\n",
        "    for _ in range(num_layers):\n",
        "        attention_output = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)(\n",
        "            query=x_dec, value=x_enc, key=x_enc)\n",
        "        attention_output = Dropout(dropout_rate)(attention_output)\n",
        "        x_dec = LayerNormalization(epsilon=1e-6)(x_dec + attention_output)\n",
        "\n",
        "        ffn_output = Dense(ff_dim, activation='relu')(x_dec)\n",
        "        ffn_output = Dense(embed_dim)(ffn_output)\n",
        "        ffn_output = Dropout(dropout_rate)(ffn_output)\n",
        "        x_dec = LayerNormalization(epsilon=1e-6)(x_dec + ffn_output)\n",
        "\n",
        "    output = Dense(vocab_size, activation=\"softmax\")(x_dec)\n",
        "    model = Model(inputs=[encoder_input, decoder_input], outputs=output)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "5AEYNk50AL-H"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "iYtAEVasBXOY"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "def preprocess_test_audio(path, max_len=2000):\n",
        "    y, sr = librosa.load(path, sr=None)\n",
        "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=64).T\n",
        "\n",
        "    if mfcc.shape[0] < max_len:\n",
        "        mfcc = np.pad(mfcc, ((0, max_len - mfcc.shape[0]), (0, 0)), mode='constant')\n",
        "    else:\n",
        "        mfcc = mfcc[:max_len, :]\n",
        "\n",
        "    return np.expand_dims(mfcc, axis=0)  # shape: (1, 2000, 64)\n",
        "\n",
        "# Example:\n",
        "test_audio_path = \"/content/drive/MyDrive/dataset2/audio/1-E1-Major 00 (1).wav\"\n",
        "test_audio = preprocess_test_audio(test_audio_path)\n"
      ],
      "metadata": {
        "id": "G-EK6L-OBlaX"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1gmRB2-NBl_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def greedy_decode(transformer, audio_input, tokenizer, max_len=256, start_token_id=101, end_token_id=102):\n",
        "    decoded_ids = [start_token_id]\n",
        "\n",
        "    for _ in range(max_len):\n",
        "        decoder_input = np.array(decoded_ids)[None, :]  # shape: (1, seq_len)\n",
        "        preds = transformer.predict([audio_input, decoder_input], verbose=0)\n",
        "\n",
        "        next_id = np.argmax(preds[0, -1, :])  # Pick highest prob token from last time step\n",
        "\n",
        "        if next_id == end_token_id:\n",
        "            break\n",
        "\n",
        "        decoded_ids.append(next_id)\n",
        "\n",
        "    return decoded_ids\n"
      ],
      "metadata": {
        "id": "4SSON6fpBxcY"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cJhaGb1fBx-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define tokenizer special token IDs\n",
        "start_token = tokenizer.cls_token_id or 101\n",
        "end_token   = tokenizer.sep_token_id or 102\n",
        "\n",
        "# Run decoding\n",
        "output_token_ids = greedy_decode(\n",
        "    transformer,\n",
        "    test_audio,\n",
        "    tokenizer,\n",
        "    max_len=256,\n",
        "    start_token_id=start_token,\n",
        "    end_token_id=end_token\n",
        ")\n",
        "\n",
        "# Convert token IDs back to string\n",
        "predicted_text = tokenizer.decode(output_token_ids, skip_special_tokens=True)\n",
        "\n",
        "# Display output\n",
        "print(\"🔍 Predicted Output:\\n\")\n",
        "print(predicted_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "PVpqVa7zB4vg",
        "outputId": "76fb5846-1422-47a0-85d5-74b38abf11c5"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "Graph execution error:\n\nDetected at node functional_13_1/positional_embedding_1_1/add defined at (most recent call last):\n<stack traces unavailable>\nIncompatible shapes: [1,101,128] vs. [1,100,128]\n\t [[{{node functional_13_1/positional_embedding_1_1/add}}]]\n\ttf2xla conversion failed while converting __inference_one_step_on_data_71655[]. Run with TF_DUMP_GRAPH_PREFIX=/path/to/dump/dir and --vmodule=xla_compiler=2 to obtain a dump of the compiled functions.\n\t [[StatefulPartitionedCall]] [Op:__inference_one_step_on_data_distributed_71840]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-90ac3ba7f234>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Run decoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m output_token_ids = greedy_decode(\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtest_audio\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-44-3b1582d9039f>\u001b[0m in \u001b[0;36mgreedy_decode\u001b[0;34m(transformer, audio_input, tokenizer, max_len, start_token_id, end_token_id)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mdecoder_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoded_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# shape: (1, seq_len)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maudio_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_input\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mnext_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Pick highest prob token from last time step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m       \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0mkeras_symbolic_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m_is_keras_symbolic_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkeras_symbolic_tensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node functional_13_1/positional_embedding_1_1/add defined at (most recent call last):\n<stack traces unavailable>\nIncompatible shapes: [1,101,128] vs. [1,100,128]\n\t [[{{node functional_13_1/positional_embedding_1_1/add}}]]\n\ttf2xla conversion failed while converting __inference_one_step_on_data_71655[]. Run with TF_DUMP_GRAPH_PREFIX=/path/to/dump/dir and --vmodule=xla_compiler=2 to obtain a dump of the compiled functions.\n\t [[StatefulPartitionedCall]] [Op:__inference_one_step_on_data_distributed_71840]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4rilYwqhB5R3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}